### Заметки

- Реализовано минимально жизнеспособное приложение (в задании мало информации).
- Структура проекта задана в соответствии с [рекомендациями](https://github.com/golang-standards/project-layout/blob/master/README_ru.md).
- Произведена попытка реализации простейшего DI для уменьшения связности кода (после .NET чувствуется сильное различие в работе с интерфейсами; в Go нужно стараться следовать правилу "принимать интерфейс, возвращать структуру").
- Все зависимости добавлены вручную (на будущее - посмотреть какие существуют DI-контейнеры для Go, городить свои велосипеды не стоит).
- Реализован репозиторий для работы с [redis](https://github.com/redis/go-redis)-хранилищем.

### Пример использования

Добавление ссылки
> http://127.0.0.1:8080/a/?url=http%3A%2F%2Fgoogle.com%2F%3Fq%3Dgolang

Вывод
> status: 200; hash: 88bc09d7

Переход по сокращенной ссылке
> http://127.0.0.1:8080/s/88bc09d7

Результат - редирект на ресурс, соответствующий сокращенной ссылке

![result!](/assets/result.png)

### Подумать, что если нужно будет хранить 1M ссылок, 10M, 100M?

В таких случаях могу возникнуть проблемы.

Медленный поиск.
Можно улучшить за счет группировки данных в [бакеты](https://www.mongodb.com/blog/post/building-with-patterns-the-bucket-pattern).
Если данных слишком много, а инстанс бд всего 1, при этом после оптимизаций скорость все равно остается не удовлетворительной,
можно прибегунть к шардированию - распределению данных одного инстанса по нескольким на разных серверах.

Коллизии.
8-ми символьный код на больших объемах данных точно приведет к коллизиям. Коллизии увеличивают время, затрачиваемое на операции с данными (разрешение коллизий и т.д.).
Нужно оценить - какие преимущества дает 8-ми символьный хеш и есть ли возможность перейти к более сложному.

Нехватка памяти (тут скорее про случай, когда требуется быстрое хранилище, использующее RAM, как, например, Redis).
Нужно посмотреть на интенсивность и объем поступающих в данных.
Хранилище подобного типа, очевидно, нужно периодически чистить.
Есть смысл для каждой записи устанавливать поле с датой создания и периодически удалять записи, время жизни которых превышает заданный порог (или использовать другую логику - токены и т.д.).
Если текущей памяти не хватает, нужно посмотреть, решит ли проблему вертикальное масштабирование.
Если не решит, то можно посмотреть опять же в сторону шардирования.
И вообще, если подобная ситуация имеет место (огромные данные в хранилище в RAM), на мой взгляд нужно задаться вопросом - а правильно ли вообще спроектирована система.
